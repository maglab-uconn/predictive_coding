{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from SRN import Model, Softmax, Sigmoid, Phase_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_Lexicon= 'ELP_groupData.csv'\n",
    "novel1_Lexicon= 'Novel_Lexicon_1.csv'\n",
    "novel2_Lexicon= 'Novel_Lexicon_2.csv'\n",
    "\n",
    "hidden_Unit= 200\n",
    "output_Function= Softmax\n",
    "\n",
    "result_Path = './Results'\n",
    "pre_Epoch= 10000\n",
    "day1_Post_Epoch= 10020\n",
    "day2_Post_Epoch= 10050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme count: 41\n",
      "Word count: 37610\n",
      "Total pronunciation length: 37610\n",
      "Weight Matrix IH shape: (41, 200)\n",
      "Weight Matrix IH shape: (200, 200)\n",
      "Weight Matrix HO shape: (200, 41)\n",
      "Bias Matrix H shape: (1, 200)\n",
      "Bias Matrix O shape: (1, 41)\n",
      "'./Results/Use_Frequency/Weight/Weight.M_Normal.E_10000.pickle' Loaded\n",
      "\n",
      "Phoneme count: 41\n",
      "Word count: 37610\n",
      "Total pronunciation length: 37610\n",
      "Weight Matrix IH shape: (41, 200)\n",
      "Weight Matrix IH shape: (200, 200)\n",
      "Weight Matrix HO shape: (200, 41)\n",
      "Bias Matrix H shape: (1, 200)\n",
      "Bias Matrix O shape: (1, 41)\n",
      "'./Results/Non_Frequency/Weight/Weight.M_Normal.E_10000.pickle' Loaded\n",
      "\n",
      "Phoneme count: 41\n",
      "Word count: 37610\n",
      "Total pronunciation length: 37610\n",
      "Weight Matrix IH shape: (41, 200)\n",
      "Weight Matrix IH shape: (200, 200)\n",
      "Weight Matrix HO shape: (200, 41)\n",
      "Bias Matrix H shape: (1, 200)\n",
      "Bias Matrix O shape: (1, 41)\n",
      "'./Results/Use_Frequency/Weight/Weight.M_Addition.E_10020.Novel1.pickle' Loaded\n",
      "\n",
      "Phoneme count: 41\n",
      "Word count: 37610\n",
      "Total pronunciation length: 37610\n",
      "Weight Matrix IH shape: (41, 200)\n",
      "Weight Matrix IH shape: (200, 200)\n",
      "Weight Matrix HO shape: (200, 41)\n",
      "Bias Matrix H shape: (1, 200)\n",
      "Bias Matrix O shape: (1, 41)\n",
      "'./Results/Non_Frequency/Weight/Weight.M_Addition.E_10020.Novel1.pickle' Loaded\n",
      "\n",
      "Phoneme count: 41\n",
      "Word count: 37610\n",
      "Total pronunciation length: 37610\n",
      "Weight Matrix IH shape: (41, 200)\n",
      "Weight Matrix IH shape: (200, 200)\n",
      "Weight Matrix HO shape: (200, 41)\n",
      "Bias Matrix H shape: (1, 200)\n",
      "Bias Matrix O shape: (1, 41)\n",
      "'./Results/Use_Frequency/Weight/Weight.M_Addition.E_10050.Novel1.pickle' Loaded\n",
      "\n",
      "Phoneme count: 41\n",
      "Word count: 37610\n",
      "Total pronunciation length: 37610\n",
      "Weight Matrix IH shape: (41, 200)\n",
      "Weight Matrix IH shape: (200, 200)\n",
      "Weight Matrix HO shape: (200, 41)\n",
      "Bias Matrix H shape: (1, 200)\n",
      "Bias Matrix O shape: (1, 41)\n",
      "'./Results/Non_Frequency/Weight/Weight.M_Addition.E_10050.Novel1.pickle' Loaded\n",
      "\n",
      "Phoneme count: 41\n",
      "Word count: 37610\n",
      "Total pronunciation length: 37610\n",
      "Weight Matrix IH shape: (41, 200)\n",
      "Weight Matrix IH shape: (200, 200)\n",
      "Weight Matrix HO shape: (200, 41)\n",
      "Bias Matrix H shape: (1, 200)\n",
      "Bias Matrix O shape: (1, 41)\n",
      "'./Results/Use_Frequency/Weight/Weight.M_Addition.E_10020.Novel2.pickle' Loaded\n",
      "\n",
      "Phoneme count: 41\n",
      "Word count: 37610\n",
      "Total pronunciation length: 37610\n",
      "Weight Matrix IH shape: (41, 200)\n",
      "Weight Matrix IH shape: (200, 200)\n",
      "Weight Matrix HO shape: (200, 41)\n",
      "Bias Matrix H shape: (1, 200)\n",
      "Bias Matrix O shape: (1, 41)\n",
      "'./Results/Non_Frequency/Weight/Weight.M_Addition.E_10020.Novel2.pickle' Loaded\n",
      "\n",
      "Phoneme count: 41\n",
      "Word count: 37610\n",
      "Total pronunciation length: 37610\n",
      "Weight Matrix IH shape: (41, 200)\n",
      "Weight Matrix IH shape: (200, 200)\n",
      "Weight Matrix HO shape: (200, 41)\n",
      "Bias Matrix H shape: (1, 200)\n",
      "Bias Matrix O shape: (1, 41)\n",
      "'./Results/Use_Frequency/Weight/Weight.M_Addition.E_10050.Novel2.pickle' Loaded\n",
      "\n",
      "Phoneme count: 41\n",
      "Word count: 37610\n",
      "Total pronunciation length: 37610\n",
      "Weight Matrix IH shape: (41, 200)\n",
      "Weight Matrix IH shape: (200, 200)\n",
      "Weight Matrix HO shape: (200, 41)\n",
      "Bias Matrix H shape: (1, 200)\n",
      "Bias Matrix O shape: (1, 41)\n",
      "'./Results/Non_Frequency/Weight/Weight.M_Addition.E_10050.Novel2.pickle' Loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_Dict = {}\n",
    "\n",
    "for lexicon_Type in ['Pre', 'Post_Novel1_Day1', 'Post_Novel1_Day2', 'Post_Novel2_Day1', 'Post_Novel2_Day2']:\n",
    "    for use_Frequency in [True, False]:\n",
    "        if 'Novel1' in lexicon_Type:\n",
    "            additional_Lexicon = novel1_Lexicon\n",
    "        elif 'Novel2' in lexicon_Type:\n",
    "            additional_Lexicon = novel2_Lexicon\n",
    "        else:\n",
    "            additional_Lexicon= None\n",
    "            \n",
    "        weight_Path = os.path.join(\n",
    "            result_Path,\n",
    "            'Use_Frequency' if use_Frequency else 'Non_Frequency',\n",
    "            'Weight',\n",
    "            'Weight.M_{}.E_{}{}.pickle'.format(            \n",
    "                'Addition' if 'Novel' in lexicon_Type else 'Normal',\n",
    "                day1_Post_Epoch if 'Day1' in lexicon_Type else day2_Post_Epoch if 'Day2' in lexicon_Type else pre_Epoch,\n",
    "                '.Novel1' if 'Novel1' in lexicon_Type else '.Novel2' if 'Novel2' in lexicon_Type else ''            \n",
    "                )            \n",
    "            ) .replace('\\\\', '/')\n",
    "        \n",
    "        model_Dict[lexicon_Type, use_Frequency] = Model(\n",
    "            hidden_Unit= hidden_Unit,\n",
    "            output_Function= output_Function,\n",
    "            lexicon_File= original_Lexicon,\n",
    "            additional_Lexicon_File= additional_Lexicon,\n",
    "            weight_File= weight_Path,\n",
    "            use_Frequency = use_Frequency\n",
    "            )\n",
    "        result_Path,\n",
    "                \n",
    "        print(f'\\'{weight_Path}\\' Loaded')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 165/165 [00:00<00:00, 369.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 165/165 [00:00<00:00, 373.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for use_Frequency in [True, False]:\n",
    "    Phase_Test(\n",
    "        pre_Model= model_Dict['Pre', use_Frequency],\n",
    "        post_Novel1_Day1_Model= model_Dict['Post_Novel1_Day1', use_Frequency],\n",
    "        post_Novel1_Day2_Model= model_Dict['Post_Novel1_Day2', use_Frequency],\n",
    "        post_Novel2_Day1_Model= model_Dict['Post_Novel2_Day1', use_Frequency],\n",
    "        post_Novel2_Day2_Model= model_Dict['Post_Novel2_Day2', use_Frequency],\n",
    "        tag= 'Use_Frequency' if use_Frequency else 'Non_Frequency',\n",
    "        export_Path= './Results'\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
