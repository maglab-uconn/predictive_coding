{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Gagnepain2012 import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = 'ELP_groupData.csv'\n",
    "novel1 = 'Novel_Lexicon_1.csv'\n",
    "novel2 = 'Novel_Lexicon_2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel1_Words = [\n",
    "    x.split(',')[2]\n",
    "    for x in open (novel1, \"r\").readlines()[1:]\n",
    "    ]\n",
    "novel2_Words = [\n",
    "    x.split(',')[2]\n",
    "    for x in open (novel2, \"r\").readlines()[1:]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Dict = {\n",
    "    ('Original', 'Non_Frequency'): Model(\n",
    "        lexicon_File = lexicon,\n",
    "        additional_Lexicon_File = None,\n",
    "        use_Frequency= False\n",
    "        ),\n",
    "    ('Post_Novel1', 'Non_Frequency'): Model(\n",
    "        lexicon_File = lexicon,\n",
    "        additional_Lexicon_File = novel1,\n",
    "        use_Frequency= False\n",
    "        ),\n",
    "    ('Post_Novel2', 'Non_Frequency'): Model(\n",
    "        lexicon_File = lexicon,\n",
    "        additional_Lexicon_File = novel2,\n",
    "        use_Frequency= False\n",
    "        ),\n",
    "    ('Original', 'Frequency'): Model(\n",
    "        lexicon_File = lexicon,\n",
    "        additional_Lexicon_File = None,\n",
    "        use_Frequency= True\n",
    "        ),\n",
    "    ('Post_Novel1', 'Frequency'): Model(\n",
    "        lexicon_File = lexicon,\n",
    "        additional_Lexicon_File = novel1,\n",
    "        use_Frequency= True\n",
    "        ),\n",
    "    ('Post_Novel2', 'Frequency'): Model(\n",
    "        lexicon_File = lexicon,\n",
    "        additional_Lexicon_File = novel2,\n",
    "        use_Frequency= True\n",
    "        ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_Labels, originals, novel1_Labels, novel1s, novel2_Labels, novel2s, *_ = zip(*[\n",
    "    x.split(',')\n",
    "    for x in open ('gagnepain_items_revised.csv', 'r').readlines()[1:]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniqueness_DIct = {\n",
    "    'Original': {},\n",
    "    'Novel1': {},\n",
    "    'Novel2': {},\n",
    "    }\n",
    "\n",
    "for lexicon in originals + novel1s + novel2s:\n",
    "    candidates = [x for x in model_Dict['Original', 'Non_Frequency'].pronunciation_Dict.values()]\n",
    "    uniqueness_Point = None\n",
    "    \n",
    "    for index in range(1, len(lexicon)):\n",
    "        candidates = [\n",
    "            candidate\n",
    "            for candidate in candidates\n",
    "            if lexicon[:index] == candidate[:index]\n",
    "            ]\n",
    "        if len(candidates) == 1:\n",
    "            uniqueness_Point = index\n",
    "            break\n",
    "    uniqueness_DIct['Original'][lexicon] = uniqueness_Point or len(lexicon) + 1\n",
    "    \n",
    "    \n",
    "for lexicon in originals + novel1s + novel2s:\n",
    "    candidates = [x for x in model_Dict['Post_Novel1', 'Non_Frequency'].pronunciation_Dict.values()]\n",
    "    uniqueness_Point = None\n",
    "    \n",
    "    for index in range(1, len(lexicon)):\n",
    "        candidates = [\n",
    "            candidate\n",
    "            for candidate in candidates\n",
    "            if lexicon[:index] == candidate[:index]\n",
    "            ]\n",
    "        if len(candidates) == 1:\n",
    "            uniqueness_Point = index\n",
    "            break\n",
    "    uniqueness_DIct['Novel1'][lexicon] = uniqueness_Point or len(lexicon) + 1\n",
    "    \n",
    "for lexicon in originals + novel1s + novel2s:\n",
    "    candidates = [x for x in model_Dict['Post_Novel2', 'Non_Frequency'].pronunciation_Dict.values()]\n",
    "    uniqueness_Point = None\n",
    "    \n",
    "    for index in range(1, len(lexicon)):\n",
    "        candidates = [\n",
    "            candidate\n",
    "            for candidate in candidates\n",
    "            if lexicon[:index] == candidate[:index]\n",
    "            ]\n",
    "        if len(candidates) == 1:\n",
    "            uniqueness_Point = index\n",
    "            break\n",
    "    uniqueness_DIct['Novel2'][lexicon] = uniqueness_Point or len(lexicon) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non_Frequency Original Original\n",
      "Non_Frequency Original Novel1\n",
      "Non_Frequency Original Novel2\n",
      "Non_Frequency Post_Novel1 Original\n",
      "Non_Frequency Post_Novel1 Novel1\n",
      "Non_Frequency Post_Novel1 Novel2\n",
      "Non_Frequency Post_Novel2 Original\n",
      "Non_Frequency Post_Novel2 Novel1\n",
      "Non_Frequency Post_Novel2 Novel2\n",
      "Frequency Original Original\n",
      "Frequency Original Novel1\n",
      "Frequency Original Novel2\n",
      "Frequency Post_Novel1 Original\n",
      "Frequency Post_Novel1 Novel1\n",
      "Frequency Post_Novel1 Novel2\n",
      "Frequency Post_Novel2 Original\n",
      "Frequency Post_Novel2 Novel1\n",
      "Frequency Post_Novel2 Novel2\n"
     ]
    }
   ],
   "source": [
    "for frequency in ['Non_Frequency', 'Frequency']:    \n",
    "    exports = ['', 'PHASE', 'TYPE', 'ORIGINAL', 'ACTUAL', 'UP', 'DP', 'position', 'position_UP', 'position_DP', 'phoneme', 'phon_prob', 'error']\n",
    "    exports = ['\\t'.join(exports)]\n",
    "        \n",
    "    for phase, model in [\n",
    "        (phase, model)\n",
    "        for (phase, use_Frequency), model in model_Dict.items()\n",
    "        if use_Frequency == frequency\n",
    "        ]:\n",
    "        for dataset in ['Original', 'Novel1', 'Novel2']:\n",
    "            print(frequency, phase, dataset)\n",
    "            for dataset_Label, labels, patterns in [\n",
    "                ('Original', original_Labels, originals),\n",
    "                ('Novel1', novel1_Labels, novel1s),\n",
    "                ('Novel2', novel2_Labels, novel2s)\n",
    "                ]:\n",
    "                for label, original, pattern in zip(labels, originals, patterns):\n",
    "                    probabilities, errors, uniqueness_Point = model.Test(pattern)                \n",
    "                    probabilities = ['{:.5f}'.format(x) for x in probabilities]\n",
    "                    errors = ['{:.5f}'.format(x) for x in errors]\n",
    "\n",
    "                    for position, (probability, error) in enumerate(zip(probabilities, errors), 1):\n",
    "                        line = [len(exports), phase, dataset_Label, original, pattern, uniqueness_DIct['Original'][original], uniqueness_DIct[dataset][pattern], position, '?', '?', pattern[position - 1], probability, error]\n",
    "                        exports.append('\\t'.join([f'{x}' for x in line]))\n",
    "                        \n",
    "    open('Gagnepain2012_Results.{}.txt'.format(frequency), 'w').write('\\n'.join(exports))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
